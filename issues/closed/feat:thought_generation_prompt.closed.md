 ## タスク概要 (Summary)

* **タスクリスト番号**: `[ ] 4.1. 思考生成プロンプト詳細化とコンテクスト整形 (core/context_builder.py, prompts/think_generate.txt)`
* **担当モジュール/ファイル**: `project_anima/core/context_builder.py` (既存ファイルに追記・修正), `project_anima/prompts/think_generate.txt` (既存ファイルを修正)
* **関連する詳細仕様書セクション**:
    * 「詳細仕様書 3.2.1. キャラクター思考プロセス (ターン処理) - 思考生成プロンプト構築」
    * 「詳細仕様書 2.3. 用語定義 (コンテクスト)」
    * 「タスク2.2で作成した `think_generate.txt` の内容」
* **このタスクのゴール**: `ContextBuilder` の各 `_format_*` メソッドを本格的に実装し、`think_generate.txt` プロンプトテンプレートと連携して、LLMがキャラクターの思考・行動・発言をより自然で深みのある形で生成できるように、コンテクスト情報の整形ロジックを詳細化する。

## 背景と目的 (Background and Purpose)

* タスク2.1で実装した `ContextBuilder` の各 `_format_*` メソッドは、現時点ではダミーの単純な文字列整形ロジックとなっている。
* LLMの応答品質はプロンプトの質に大きく依存するため、キャラクターの性格、経験、現在の状況などを効果的にLLMに伝え、より「それらしい」応答を引き出すための本格的なプロンプトエンジニアリングを行う必要がある。
* このタスクでは、各コンテクスト情報をどのようにLLMに提示すれば、キャラクターの思考の深みや一貫性が増すかを検討し、`ContextBuilder` と `think_generate.txt` を連携させてその整形ロジックを実装する。

## 実装する機能の詳細 (Detailed Functionality to Implement)

* **対象ファイルと主な修正箇所**:
    * **`project_anima/prompts/think_generate.txt`**:
        * タスク2.2で作成した雛形をベースに、より効果的な指示や役割設定、コンテクスト情報の提示方法を検討し、記述を修正・詳細化する。
        * 例えば、各コンテクスト情報のセクションに見出しをつけたり、LLMに対する役割（例：「あなたはキャラクター〇〇です」）をより明確にしたり、思考の深さを求めるような指示を追加したりする。
        * 「コンテクストの統合的理解」で指示したような、各情報の関連性をLLMが理解しやすいような記述を強化する。
    * **`project_anima/core/context_builder.py`**:
        * `_format_immutable_context` メソッド:
            * `ImmutableCharacterData` の各フィールドを、`think_generate.txt` のプレースホルダーに対応する形で、意味が通じる自然な文章や箇条書きに整形する。
            * 例: 「名前: アリス\n年齢: 17歳\n職業: 高校生\n性格: 好奇心旺盛で、少しおっちょこちょい。新しいことや不思議なことに出会うと、じっとしていられないタイプ。友達思いで、困っている人を見ると放っておけない優しさも持っている。」のように、単なるキーと値の羅列ではなく、説明的なテキストにする。
        * `_format_long_term_context` メソッド:
            * `LongTermCharacterData` の `experiences`, `goals`, `memories` を、それぞれ読みやすいリスト形式や物語調の記述に整形する。
            * **情報量の制御**: 長期情報は時間とともに増大する可能性があるため、全ての情報をそのまま渡すとコンテクスト長を圧迫する。この段階で、例えば「直近のN件の記憶」や「重要度の高い目標上位M件」のように、情報をフィルタリングまたは要約する簡易的なロジックを導入することを検討する（本格的なRAGのような仕組みは将来のタスク）。
            * 例:
                ```
                【経験】
                - 幼い頃、森で不思議な光る蝶々を追いかけて迷子になったことがある。(重要度: 高)
                - 中学の時、親友と一緒に文化祭の演劇で主役を演じ、大成功を収めた。(重要度: 中)
                【目標】
                - この世界の謎や不思議な現象の秘密を解き明かしたい。(重要度: 極めて高い)
                - たくさんの友達を作って、毎日を楽しく過ごしたい。(重要度: 高い)
                【最近の記憶】
                - 昨日、図書室でボブくんに「その本、面白いよね」と声をかけられた。(場面: S001)
                ```
        * `_format_scene_context` メソッド:
            * `SceneInfoData` の各フィールドを、場面の状況が明確に伝わるように整形する。参加キャラクター名は、単なるIDのリストではなく、名前のリストとして提示する。
            * 例: 「現在地は「放課後の教室」です。時刻は「夕方」。状況は「夕日が窓から差し込み、机と椅子が整然と並んでいる。誰もいないように見える。」参加者はアリス、ボブです。」
        * `_format_short_term_context` メソッド:
            * `List[TurnData]` (直近の会話・行動履歴) を、LLMが会話の流れを理解しやすいように、発言者と発言内容が明確な対話形式の文字列に整形する。思考や行動も適切に含める。
            * **情報量の制御**: 短期ログも長くなる可能性があるため、直近の数ターン（例: 5～10ターン）に限定してコンテクストに含めるなどの制御を検討する。
            * 例:
                ```
                【最近のやり取り】
                アリス: 「こんにちは、ボブくん。」（少し緊張しながら微笑む）
                ボブ: （アリスに気づき、少し驚いた表情で）「あ、アリスさん。こんにちは。」
                アリス: （内心: 何を話そうかな…ボブくん、なんだかいつもと雰囲気が違うような…）
                ```
* **`ContextBuilder.build_context_for_character` メソッドの修正**:
    * 各 `_format_*` メソッドの返り値が更新されたことに伴い、これらの整形済み文字列を結合して最終的なプロンプト文字列（またはプロンプトに埋め込むための辞書の値）を生成するロジックを確認・調整する。
    * Issue for Task 2.1 のレビューで合意した通り、このメソッドは各整形済みコンテクスト文字列と、それらを全て結合した `full_context` を含む辞書を返す。
* **エラーハンドリング**: 各 `_format_*` メソッド内で、入力データが予期せず `None` だった場合などの基本的なガード処理を行う。
* **考慮事項**:
    * **プロンプトの明確性と具体性**: LLMが役割を理解し、期待される形式で応答を生成できるように、指示は明確かつ具体的にする。
    * **コンテクストのバランス**: 不変情報、長期情報、場面情報、短期情報の各要素が、キャラクターの思考にバランス良く影響を与えるように、それぞれの情報量や提示方法を調整する。
    * **「らしさ」の追求**: キャラクターの性格や口調が応答に反映されるようなプロンプトの工夫を意識する（本格的な調整は後のタスクだが、この段階から意識する）。

---

### 具体的な実装指示 (Specific Implementation Instructions for AI Assistant: Cursor)

**(ここからはAIアシスタントであるCursorへの具体的な指示を記述する)**

**1. 対象ファイルの編集:**

* **`project_anima/prompts/think_generate.txt`**:
    * タスク2.2で作成した雛形をベースに、上記「実装する機能の詳細」で検討したような、より詳細な役割設定、コンテクスト情報の提示方法、思考プロセスの指示（コンテクストの統合的理解→思考→行動→発言）などを追記・修正してください。
    * 各コンテクスト情報を埋め込むプレースホルダー (`{{immutable_context_str}}` など) は維持しつつ、その周囲の指示文を強化してください。

* **`project_anima/core/context_builder.py`**:
    * `_format_immutable_context`, `_format_long_term_context`, `_format_scene_context`, `_format_short_term_context` の各メソッドを、上記「実装する機能の詳細」で説明した方針に従って、ダミー実装から本格的な文字列整形ロジックに書き換えてください。
    * 特に長期情報と短期情報については、情報量を適切に制御する（例: 最新N件、重要度順など）ための簡易的なフィルタリング/サマリーロジックを導入してください。
    * `build_context_for_character` メソッドが、これらの整形済み文字列を正しく辞書に格納して返すことを確認してください。

**2. 実装ロジックの詳細 (各 `_format_*` メソッド):**

* **`_format_immutable_context`**:
    * `immutable_data` の各フィールドを、人間が読みやすい説明的な文章として結合してください。

* **`_format_long_term_context`**:
    * `experiences`, `goals`, `memories` のリストを反復処理し、それぞれ箇条書き形式などで整形してください。
    * **情報量制御の例**:
        * `experiences`: 最新3件と重要度が高いもの上位2件を組み合わせる、など。
        * `goals`: 重要度が高いもの上位3件を表示する、など。
        * `memories`: 最新5件を表示する、など。
        * (これらの具体的な数値やロジックは、まずはシンプルなものから実装し、調整は後続のタスクで行います。)

* **`_format_scene_context`**:
    * `scene_data` の情報を自然な文章で説明するようにしてください。
    * 参加キャラクター名は、`CharacterManager` を使ってIDから名前に変換して表示してください。変換に失敗した場合はIDをそのまま表示するフォールバックも考慮してください。

* **`_format_short_term_context`**:
    * `short_term_log` (ターンのリスト) を、キャラクター名と発言・行動が交互に現れるような対話形式の文字列にしてください。
    * **情報量制御の例**: 最新5ターン分のみを整形対象とする、など。
    * 各ターンの「思考」は、プロンプトの種類によっては含めない方が良い場合もあるため、ここでは「発言」と「行動」を中心に整形することを推奨します。「思考」を含めるかどうかは、`think_generate.txt` の指示と合わせて調整してください。

**3. コーディング規約・その他指示:**

* Pythonの型ヒント、docstring、コメントは引き続き丁寧に記述してください。
* 文字列の結合や整形には、f-stringや `str.join()` などを効果的に使用してください。
* 情報量制御のためのロジックは、現時点では複雑にしすぎず、設定値（例: 表示する最大件数）をクラスの定数やメソッドの引数として持たせることも検討してください。

---

## テストケース (Test Cases)

**(このタスクの完了を確認するためのテストケースをTDDの観点から記述)**

### 前提: モックオブジェクトとテストデータ準備
* `CharacterManager` と `SceneManager` のモック、およびそれらが返すテスト用の `ImmutableCharacterData`, `LongTermCharacterData`, `SceneInfoData`, `TurnData` のインスタンスを準備する (タスク2.1のテスト資産を流用・拡張)。
* `LongTermCharacterData` には、経験・目標・記憶がそれぞれ複数件含まれるようにデータを準備する。
* `short_term_log` にも複数ターンのデータを準備する。

### 正常系テスト

1.  **テストケース1: 全てのコンテクスト情報が詳細に整形される**
    * **前提条件/入力**: 全てのコンテクスト情報が利用可能な状態で `ContextBuilder` を初期化。
    * **操作手順**: `context_builder.build_context_for_character("test_char_id", dummy_short_term_log)` を実行。
    * **期待される結果**: 返される辞書の各キー (`"immutable_context_str"`, `"long_term_context_str"`, `"scene_context_str"`, `"short_term_context_str"`) に対応する値が、それぞれの `_format_*` メソッドによって詳細かつ適切に整形された文字列であること。特に長期情報と短期情報については、情報量制御のロジック（例: 最新N件など）が適用された結果の文字列になっていることを確認する。
2.  **テストケース2: 長期情報が空の場合の整形**
    * **前提条件/入力**: `LongTermCharacterData` の `experiences`, `goals`, `memories` が全て空リスト。
    * **操作手順**: `context_builder.build_context_for_character(...)` を実行。
    * **期待される結果**: `"long_term_context_str"` が、「経験はありません。」「目標はありません。」「記憶はありません。」のような、情報がないことを示す適切な文字列になること。
3.  **テストケース3: 短期ログが非常に長い場合の整形 (情報量制御の確認)**
    * **前提条件/入力**: `short_term_log` に10件以上のターンデータが含まれる。
    * **操作手順**: `context_builder.build_context_for_character(...)` を実行。
    * **期待される結果**: `"short_term_context_str"` が、設定された最大件数（例: 最新5件）のターンのみを含む文字列になっていること。

### 異常系テスト (主に `_format_*` メソッドの入力が予期せず `None` だった場合など)

1.  **テストケース1: `_format_immutable_context` に `None` が渡された場合 (CharacterManagerがエラーを返さなかった場合など)**
    * **操作手順**: `context_builder._format_immutable_context(None)` を直接呼び出す (テストのため)。
    * **期待される結果**: メソッドが `TypeError` や `AttributeError` を発生させるか、あるいは「不変情報がありません」のようなデフォルト文字列を返すなど、安全に処理されること (Docstringに明記)。
    * (他の `_format_*` メソッドについても同様のテストを検討)

## 完了の定義 (Definition of Done)

* [ ] `project_anima/prompts/think_generate.txt` が修正され、LLMへの指示やコンテクスト情報の提示方法がより詳細かつ効果的になっている。
* [ ] `project_anima/core/context_builder.py` の `_format_immutable_context`, `_format_long_term_context`, `_format_scene_context`, `_format_short_term_context` メソッドが、ダミー実装から本格的な文字列整形ロジックに書き換えられている。
* [ ] 長期情報と短期情報の整形において、情報量を適切に制御するための簡易的なフィルタリング/サマリーロジックが導入されている。
* [ ] `build_context_for_character` メソッドが、整形された各コンテクスト文字列と、それらを結合した `full_context` を含む辞書を正しく返す。
* [ ] 各メソッドには適切な型ヒントとdocstringが付与されている。
* [ ] 上記テストケース（正常系・異常系）を満たすユニットテストが作成され（例: `project_anima/tests/test_context_builder.py` を拡張）、全て成功する。
* [ ] コードに明らかなバグや非効率な箇所がない。

## 備考 (Notes)

* このタスクはプロンプトエンジニアリングの第一歩です。LLMの応答を見ながら、プロンプトテンプレート (`think_generate.txt`) とコンテクスト整形ロジック (`ContextBuilder` の `_format_*` メソッド) は、今後も継続的に改善していくことになります。
* 情報量制御のロジック（何件表示するか、どのように要約するかなど）は、まずはシンプルなルールで実装し、効果を見ながら調整していきましょう。
* `think_generate.txt` のプレースホルダー名と、`ContextBuilder` が生成する辞書のキー名は、完全に一致している必要があります。